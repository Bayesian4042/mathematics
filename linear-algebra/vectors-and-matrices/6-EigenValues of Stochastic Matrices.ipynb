{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Eigenvectors and Eigenvalues\n",
    "\n",
    "**What happens when matrix hits the vector?**\n",
    "\n",
    "The vector get transformed into a new vector, it strays from it's path or vector may get scaled in the process.\n",
    "For a given matrix A, there exist a special vector which refuse to stray from their path. These vector are called eigen vectors.\n",
    "\n",
    "$$ Ax = \\lambda x $$ [direction remains the same]\n",
    "\n",
    "The vector will only get scaled but not change it's direction.\n",
    "            \n",
    "\n",
    "## Why Eigenvectors are special ?\n",
    "It turns out that various properties of matrices can be analysed based on their eigen values for example in spectral graph theory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of dominant eigen vector and dominant eigen value.\n",
    "\n",
    "Let $ \\lambda_1, \\lambda_2 , \\lambda_3 ... \\lambda_n $ be an eignen value of n x n matrix A. $ \\lambda_1 is called $ dominant eigen value of A if \n",
    "        $ \\lvert \\lambda_1 \\rvert > \\lvert \\lambda_i \\rvert, i = 2, 3 .. n $\n",
    " \n",
    " The eigenvectors corresponding to the \\lambda_1  is dominant eigenvector of A.\n",
    " \n",
    " \n",
    " # Defintion : Stochastic Matrix\n",
    " \n",
    " A matrix M is called stochastic matrix if all the entries are positive and the sum of elements in each column is 1.\n",
    " \n",
    " \n",
    " # Theorem : The largest (dominant)| eigen value of stochastic matrix is 1.\n",
    " \n",
    " see proof here [https://yutsumura.com/eigenvalues-of-a-stochastic-matrix-is-always-less-than-or-equal-to-1/]\n",
    " \n",
    " \n",
    " # Theorem : \n",
    " if A is an n x n sqaure matrix with dominant eigenvalues, then the sequence of vectors given by $ Av_0,  A^{2}v_0, A^{3}v_0, .... $ approchaes a multiple of eigenvector of A. \n",
    " \n",
    " Let $e_d$ be the dominant eigenvector of M and  $λ_d = 1$ the corresponding dominant eigenvalue. \n",
    " \n",
    " Given the previous definitions and theorems, what can you say about the sequence $ Mv(0), M^{2}v(0), M^{3}v(0), . . . $ ?\n",
    " \n",
    "there exist an n such that :\n",
    " \n",
    "$ v(n) =  M^{n} v(0) = ke_d $ (some multiple of $e_d$)\n",
    "         \n",
    "$ v(n+1) = Mv(n) = M(ke_d) = k(Me_d) = k(λ_de_d) = ke_d$\n",
    "\n",
    "Now instead of a stochastic matrix let us consider any square matrix A\n",
    "\n",
    "Let p be the time step at which the sequence $x_0, Ax_0, A^{2}x_0, . . . $ approaches a multiple of $e_d$ (the dominant eigenvector of A)\n",
    "\n",
    "$ A^{p}x_0 = ke_d $\n",
    "\n",
    "$ A^{p+1}x_0 = A(A^{p}x_0) = kAe_d = kλ_de_d $\n",
    "\n",
    "$ A^{p+2}x_0 = A(A^{p+1}x_0) = kλ_dAe_d = k(λ_d)^{2}e_d $\n",
    "\n",
    "$ A^{p+n}x_0 = k(λ_d)^{n}e_d $\n",
    "\n",
    "\n",
    "\n",
    "In general, if $λ_d$ is the dominant eigenvalue of a matrix A, what would happen to the sequence $x_0, Ax_0, A^{2}x_0, . . . $ if\n",
    "\n",
    "|λ_d| > 1 (will explode)\n",
    "\n",
    "|λ_d| < 1 (will vanish)\n",
    "\n",
    "|λ_d| = 1 (will reach a steady state)\n",
    "\n",
    "We will see this in gradient explosion and vanshing problem while training neural networks.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
